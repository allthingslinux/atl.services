// ============================================
// GRAFANA ALLOY - CENTRAL METRICS STACK
// ============================================
// This configuration collects telemetry from the central atl.services stack
// and forwards it to Mimir (metrics) and Loki (logs).
//
// Pipeline Architecture:
//   Logs:    loki.source.docker → loki.process → loki.write → Loki
//   Metrics: prometheus.scrape → prometheus.remote_write → Mimir
//
// Reference: https://grafana.com/docs/alloy/latest/collect/
// ============================================

// ============================================
// LIVE DEBUGGING
// ============================================
// Enable live debugging to stream real-time component data to the Alloy UI
// Access the UI at http://localhost:12345 to monitor pipeline health
// Reference: https://grafana.com/docs/alloy/latest/troubleshoot/debug/#live-debugging-page
livedebugging {
  enabled = true
}

// ============================================
// LOGGING PIPELINE
// ============================================

// Collect Docker container logs from all running containers
// Component: loki.source.docker
// Reference: https://grafana.com/docs/alloy/latest/reference/components/loki/loki.source.docker/
loki.source.docker "containers" {
  host       = "unix:///var/run/docker.sock"
  targets    = []
  forward_to = [loki.process.scrub_logs.receiver]
  
  relabel_rules {
    source_labels = ["__meta_docker_container_name"]
    target_label  = "container"
  }
}

// Process logs to scrub sensitive data (PII, credentials, etc.)
// This is a production-readiness step to prevent leaking sensitive information
// Component: loki.process
// Reference: https://grafana.com/docs/alloy/latest/reference/components/loki/loki.process/
loki.process "scrub_logs" {
  forward_to = [loki.write.default.receiver]
  
  stage.replace {
    expression = "(\\d{1,3}\\.){3}\\d{1,3}"
    replace = "***IP***"
  }
  stage.replace {
    expression = "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}"
    replace = "***EMAIL***"
  }
}

// Forward processed logs to Loki
// Component: loki.write
// Reference: https://grafana.com/docs/alloy/latest/reference/components/loki/loki.write/
loki.write "default" {
  endpoint {
    url = "http://loki:3100/loki/api/v1/push"
  }
}

// ============================================
// METRICS PIPELINE
// ============================================

// Forward metrics to Grafana Mimir (Prometheus-compatible remote write)
// Component: prometheus.remote_write
// Reference: https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.remote_write/
prometheus.remote_write "default" {
  endpoint {
    url = "http://mimir:8080/api/v1/push"
  }
}

// ============================================
// METRICS SCRAPE JOBS
// ============================================
// These jobs collect metrics from various exporters and services.
// Pattern: prometheus.scrape → prometheus.remote_write → Mimir
// Reference: https://grafana.com/docs/alloy/latest/collect/prometheus-metrics/

// ============================================
// Host & Container Metrics
// ============================================

// Node Exporter: Host-level metrics (CPU, memory, disk, network)
// Provides the foundation for infrastructure monitoring
prometheus.scrape "node_exporter" {
  targets = [{"__address__" = "node-exporter:9100"}]
  job_name = "node-exporter"
  forward_to = [prometheus.remote_write.default.receiver]
}

// cAdvisor: Container-level metrics (CPU throttling, memory usage, OOM kills)
// Essential for detecting container resource issues
prometheus.scrape "cadvisor" {
  targets = [{"__address__" = "cadvisor:8080"}]
  job_name = "cadvisor"
  forward_to = [prometheus.remote_write.default.receiver]
}

// ============================================
// Database & Service Exporters
// ============================================
// Collect metrics from database and service-specific exporters
// Each exporter provides deep insights into service health
prometheus.scrape "service_exporters" {
  targets = [
    {"__address__" = "postgres-exporter-xmpp:9187", "job" = "postgres-xmpp"},
    {"__address__" = "postgres-exporter-tux:9187", "job" = "postgres-tux"},
    {"__address__" = "postgres-exporter-iso:9187", "job" = "postgres-iso"},
    {"__address__" = "redis-exporter-tux:9121", "job" = "valkey-tux"},
    {"__address__" = "redis-exporter-wiki:9121", "job" = "valkey-wiki"},
    {"__address__" = "mysql-exporter-wiki:9104", "job" = "mariadb-wiki"},
    {"__address__" = "nginx-exporter-wiki:9113", "job" = "nginx-wiki"},
    {"__address__" = "cloudflare-exporter:9199", "job" = "cloudflare-exporter"},
  ]
  forward_to = [prometheus.remote_write.default.receiver]
}

// ============================================
// Application Services
// ============================================
// Services that expose Prometheus metrics directly
prometheus.scrape "local_services" {
  targets = [
    {"__address__" = "gatus:8080", "job" = "gatus"},
    {"__address__" = "blocky:4000", "job" = "blocky"},
    {"__address__" = "sftpgo:10000", "job" = "sftpgo"},
    {"__address__" = "influxdb2:8086", "job" = "influxdb2"},
  ]
  forward_to = [prometheus.remote_write.default.receiver]
}

// ============================================
// Cross-Stack Service Metrics
// ============================================
// These services run in other stacks but are accessible via shared Docker networks
// (atl-chat, tux, wiki-network are attached to this stack)

prometheus.scrape "prosody" {
  targets = [{"__address__" = "atl-xmpp-server:5280"}]
  metrics_path = "/metrics"
  job_name = "prosody"
  forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.scrape "unrealircd" {
  targets = [{"__address__" = "atl-irc-server:8600"}]
  job_name = "unrealircd"
  forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.scrape "keycloak" {
  targets = [{"__address__" = "iso_keycloak:8080"}]
  metrics_path = "/metrics"
  job_name = "keycloak"
  forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.scrape "minio_wiki" {
  targets = [{"__address__" = "local-wiki-minio:9000"}]
  metrics_path = "/minio/v2/metrics/cluster"
  job_name = "minio-wiki"
  forward_to = [prometheus.remote_write.default.receiver]
}

// ============================================
// Black-Box Monitoring (Synthetic Checks)
// ============================================
// Probes external endpoints to verify availability and response times
// This implements "symptom-based monitoring" - what users actually experience
// Reference: https://grafana.com/docs/alloy/latest/collect/prometheus-metrics/#collect-metrics-from-custom-targets

prometheus.scrape "blackbox" {
  targets = [
    {"__address__" = "https://metrics.atl.services", "module" = "http_2xx"},
    {"__address__" = "https://chat.atl.services",    "module" = "http_2xx"},
    {"__address__" = "https://wiki.atl.services",    "module" = "http_2xx"},
    {"__address__" = "https://iso.atl.dev",          "module" = "http_2xx"},
  ]
  metrics_path = "/probe"
  job_name = "blackbox"
  
  // Relabeling: Transform targets for blackbox exporter
  // Pattern: __address__ → __param_target, then replace __address__ with exporter location
  relabel_rules {
    source_labels = ["__address__"]
    target_label  = "__param_target"
  }
  relabel_rules {
    source_labels = ["__param_target"]
    target_label  = "instance"
  }
  relabel_rules {
    source_labels = ["module"]
    target_label  = "__param_module"
  }
  relabel_rules {
    target_label = "__address__"
    replacement  = "blackbox:9115"
  }
  
  forward_to = [prometheus.remote_write.default.receiver]
}

// Scrape the blackbox exporter's own metrics (meta-monitoring)
prometheus.scrape "blackbox_exporter" {
  targets = [{"__address__" = "blackbox:9115"}]
  job_name = "blackbox-exporter"
  forward_to = [prometheus.remote_write.default.receiver]
}
